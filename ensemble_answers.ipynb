{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "# sys.argv=['']\n",
    "HOME_DIR = os.getenv('HOME')\n",
    "DATA_DIR = '{}/research_backup/pytorch-transformers/data'.format(os.getenv('HOME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import ujson as json\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "def normalize_answer(s):\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    normalized_prediction = normalize_answer(prediction)\n",
    "    normalized_ground_truth = normalize_answer(ground_truth)\n",
    "\n",
    "    ZERO_METRIC = (0, 0, 0)\n",
    "\n",
    "    if normalized_prediction in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\n",
    "        return ZERO_METRIC\n",
    "    if normalized_ground_truth in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\n",
    "        return ZERO_METRIC\n",
    "\n",
    "    prediction_tokens = normalized_prediction.split()\n",
    "    ground_truth_tokens = normalized_ground_truth.split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return ZERO_METRIC\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1, precision, recall\n",
    "\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "def update_answer(metrics, prediction, gold):\n",
    "    em = exact_match_score(prediction, gold)\n",
    "    f1, prec, recall = f1_score(prediction, gold)\n",
    "    metrics['em'] += float(em)\n",
    "    metrics['f1'] += f1\n",
    "    metrics['prec'] += prec\n",
    "    metrics['recall'] += recall\n",
    "    metrics['total'] += 1\n",
    "    return em, prec, recall, f1\n",
    "\n",
    "def update_sp(metrics, prediction, gold):\n",
    "    cur_sp_pred = set(map(tuple, prediction))\n",
    "    gold_sp_pred = set(map(tuple, gold))\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    for e in cur_sp_pred:\n",
    "        if e in gold_sp_pred:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    for e in gold_sp_pred:\n",
    "        if e not in cur_sp_pred:\n",
    "            fn += 1\n",
    "    prec = 1.0 * tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = 1.0 * tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    f1 = 2 * prec * recall / (prec + recall) if prec + recall > 0 else 0.0\n",
    "    em = 1.0 if fp + fn == 0 else 0.0\n",
    "    metrics['sp_em'] += em\n",
    "    metrics['sp_f1'] += f1\n",
    "    metrics['sp_prec'] += prec\n",
    "    metrics['sp_recall'] += recall\n",
    "    return em, prec, recall\n",
    "\n",
    "def eval(prediction_file, gold_file):\n",
    "    with open(prediction_file) as f:\n",
    "        prediction = json.load(f)\n",
    "    with open(gold_file) as f:\n",
    "        gold = json.load(f)\n",
    "    with open('/'.join(gold_file.split('/')[:-1] + ['hotpot_dev_1hop_solv_nonsolv.json'])) as f:\n",
    "        onehop_ids = set(json.load(f)['1hop_solv'])\n",
    "\n",
    "    metrics = {'em': 0, 'f1': 0, 'prec': 0, 'recall': 0, 'total': 0,\n",
    "        'sp_em': 0, 'sp_f1': 0, 'sp_prec': 0, 'sp_recall': 0,\n",
    "        'joint_em': 0, 'joint_f1': 0, 'joint_prec': 0, 'joint_recall': 0}\n",
    "    subset_metrics = {subset: {'em': 0, 'f1': 0, 'prec': 0, 'recall': 0, 'total': 0}\n",
    "                      for subset in ['bridge', 'comparison', 'onehop', 'multihop']}\n",
    "    for dp in gold:\n",
    "        cur_id = dp['_id']\n",
    "        can_eval_joint = True\n",
    "        if cur_id not in prediction['answer']:\n",
    "            print('missing answer {}'.format(cur_id))\n",
    "            can_eval_joint = False\n",
    "        else:\n",
    "            em, prec, recall, f1 = update_answer(\n",
    "                metrics, prediction['answer'][cur_id], dp['answer'])\n",
    "            _ = update_answer(\n",
    "                subset_metrics['onehop' if cur_id in onehop_ids else 'multihop'],\n",
    "                prediction['answer'][cur_id], dp['answer'])\n",
    "            _ = update_answer(\n",
    "                subset_metrics[dp['type']], prediction['answer'][cur_id], dp['answer'])\n",
    "        if cur_id not in prediction['sp']:\n",
    "            print('missing sp fact {}'.format(cur_id))\n",
    "            can_eval_joint = False\n",
    "        else:\n",
    "            sp_em, sp_prec, sp_recall = update_sp(\n",
    "                metrics, prediction['sp'][cur_id], dp['supporting_facts'])\n",
    "\n",
    "        if can_eval_joint:\n",
    "            joint_prec = prec * sp_prec\n",
    "            joint_recall = recall * sp_recall\n",
    "            if joint_prec + joint_recall > 0:\n",
    "                joint_f1 = 2 * joint_prec * joint_recall / (joint_prec + joint_recall)\n",
    "            else:\n",
    "                joint_f1 = 0.\n",
    "            joint_em = em * sp_em\n",
    "\n",
    "            metrics['joint_em'] += joint_em\n",
    "            metrics['joint_f1'] += joint_f1\n",
    "            metrics['joint_prec'] += joint_prec\n",
    "            metrics['joint_recall'] += joint_recall\n",
    "\n",
    "    N = len(gold)\n",
    "    for k in metrics.keys():\n",
    "        metrics[k] /= N\n",
    "    metrics.pop('total')\n",
    "    for subset in subset_metrics.keys():\n",
    "        for k in subset_metrics[subset].keys():\n",
    "            if (k != 'total') and (subset_metrics[subset]['total'] != 0):\n",
    "                metrics[subset + '_' + k] = subset_metrics[subset][k] / subset_metrics[subset]['total']\n",
    "\n",
    "#     print(json.dumps(metrics, indent=2, sort_keys=True))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--pred_answer_file_pattern\",\n",
    "                    default=None,  # Default file pattern is set later if no flag passed.\n",
    "                    type=str,\n",
    "                    help=\"Pattern for files to aggregate. Replace seed value for '{}'.\")\n",
    "parser.add_argument(\"--num_seeds\",\n",
    "                    default=10,  # TODO: Sweep\n",
    "                    type=int,\n",
    "                    help=\"Ensemble over first N seeds\")\n",
    "parser.add_argument(\"--decay_factor\",\n",
    "                    default=1.0,  # TODO: Sweep\n",
    "                    type=float,\n",
    "                    help=\"How much to decay influence of later runs compared to earlier runs\")\n",
    "parser.add_argument(\"--num_train\",\n",
    "                    default=17435,  # TODO: Sweep: 1090 2179 4359 8718 17435\n",
    "                    type=int,\n",
    "                    help=\"Number of model training examples\")\n",
    "parser.add_argument(\"--beam\",\n",
    "                    default=10,\n",
    "                    type=int,\n",
    "                    help=\"Beam size used for generations\")\n",
    "parser.add_argument(\"--sample_temperature\",\n",
    "                    default=0.0,\n",
    "                    type=float,\n",
    "                    help=\"Softmax temperature used for sampling generations\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "# Set filename if necessary\n",
    "learning_rate = '2e-5' if args.num_train == 17435 else '3e-5'\n",
    "empty = '{}'\n",
    "if args.pred_answer_file_pattern is None:\n",
    "    args.pred_answer_file_pattern = f'{HOME_DIR}/research_backup/pytorch-transformers/checkpoint/v4.eval.num_shards=10.tn=hotpot-all.umt.comparison.paired.model=1.st={args.sample_temperature}.beam={args.beam}.lp=1.0.seed={empty}.q-predsubqs-predsubas.suba1=0.suba2=0.bs=16.lr={learning_rate}.nt={args.num_train}.st={args.sample_temperature}.seed={empty}/hotpot_predictions_.json'\n",
    "\n",
    "# Read in answers into a user-friendly data structure\n",
    "num_sample_answers = []\n",
    "qid2answer2weight = {}\n",
    "for seed in range(1, 1 + args.num_seeds):\n",
    "    with open(args.pred_answer_file_pattern.format(seed, seed)) as f:\n",
    "        sample_answers = json.load(f)['answer']\n",
    "    \n",
    "    num_sample_answers.append(len(sample_answers))\n",
    "    for qid, answer in sample_answers.items():\n",
    "        qid2answer2weight[qid] = qid2answer2weight.get(qid, {})\n",
    "        qid2answer2weight[qid][answer] = qid2answer2weight[qid].get(answer, 0)\n",
    "        qid2answer2weight[qid][answer] += args.decay_factor ** (seed - 1)\n",
    "\n",
    "assert len(set(num_sample_answers)) == 1, 'Some samples do not have the same number of predicted answers!'\n",
    "num_answers = num_sample_answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no': 556, 'no ': 23, 'yes': 367, 'yes no': 15, 'yes no ': 7}\n",
      "4.65% yes/no answers with extra text\n"
     ]
    }
   ],
   "source": [
    "# How often is there a weird answer?\n",
    "answer2count = {}\n",
    "for qid, answer2weight in qid2answer2weight.items():\n",
    "    for answer, weight in answer2weight.items():\n",
    "        if answer in {'yes', 'no', 'yes no'}:\n",
    "            answer2count[answer] = answer2count.get(answer, 0)\n",
    "            answer2count[answer] += 1\n",
    "        for answer_start in ['no ', 'yes no ']:\n",
    "            if answer.startswith(answer_start):\n",
    "                answer2count[answer_start] = answer2count.get(answer_start, 0)\n",
    "                answer2count[answer_start] += 1\n",
    "# pprint(answer2count)\n",
    "yes_no_extra = (answer2count['no '] + answer2count['yes no '] + answer2count['yes no']) / float((sum(answer2count.values())))\n",
    "# print(f'{round(100 * yes_no_extra, 2)}% yes/no answers with extra text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: 0.00040513166779203237,\n",
      " 4: 0.0009453072248480755,\n",
      " 5: 0.0037812288993923047,\n",
      " 6: 0.007427413909520602,\n",
      " 7: 0.009993247805536811,\n",
      " 8: 0.013234301147873075,\n",
      " 9: 0.022687373396353846,\n",
      " 10: 0.9415259959486009}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weightdist2count = {}\n",
    "for qid, answer2weight in qid2answer2weight.items():\n",
    "    weightdist = max(answer2weight.values())\n",
    "#     weightdist.sort(reverse=True)\n",
    "#     weightdist = tuple(weightdist)\n",
    "    weightdist2count[weightdist] = weightdist2count.get(weightdist, 0)\n",
    "    weightdist2count[weightdist] += 1. / num_answers\n",
    "# pprint(weightdist2count)\n",
    "\n",
    "# Plot\n",
    "x, y = zip(*sorted(weightdist2count.items()))\n",
    "x = np.array(x)\n",
    "y = np.array(y) * 100.\n",
    "\n",
    "plt.bar(x[:-1], y[:-1])\n",
    "plt.title('Answer Agreement across Sampled Sub-Qs')\n",
    "plt.xlabel('Agreement on Top Predicted Answer (out of 10)')\n",
    "plt.ylabel('% of Dev Examples')\n",
    "plt.savefig('/Users/ethanperez/research_backup/scripts/answer-agreement-across-sampled-sub-qs.png', dpi=200)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"bridge_em\":0.0153768165,\n",
      "  \"bridge_f1\":0.0397007157,\n",
      "  \"bridge_prec\":0.0403085528,\n",
      "  \"bridge_recall\":0.0530987909,\n",
      "  \"comparison_em\":0.6442501681,\n",
      "  \"comparison_f1\":0.701222665,\n",
      "  \"comparison_prec\":0.7160318722,\n",
      "  \"comparison_recall\":0.7071567262,\n",
      "  \"em\":0.1416610398,\n",
      "  \"f1\":0.1725411126,\n",
      "  \"joint_em\":0.0,\n",
      "  \"joint_f1\":0.0,\n",
      "  \"joint_prec\":0.0,\n",
      "  \"joint_recall\":0.0,\n",
      "  \"multihop_em\":0.2053279719,\n",
      "  \"multihop_f1\":0.2303561326,\n",
      "  \"multihop_prec\":0.2342228927,\n",
      "  \"multihop_recall\":0.2388764082,\n",
      "  \"onehop_em\":0.0677174548,\n",
      "  \"onehop_f1\":0.1053940126,\n",
      "  \"onehop_prec\":0.1083807704,\n",
      "  \"onehop_recall\":0.1212175914,\n",
      "  \"prec\":0.1760007305,\n",
      "  \"recall\":0.1844403371,\n",
      "  \"sp_em\":0.0,\n",
      "  \"sp_f1\":0.0,\n",
      "  \"sp_prec\":0.0,\n",
      "  \"sp_recall\":0.0\n",
      "}\n",
      "comparison_f1: 70.12226650232294\n"
     ]
    }
   ],
   "source": [
    "# Get best answer based on counts\n",
    "pred_answer_dict = {'answer': {}, 'sp': {}}\n",
    "for qid, answer2weight in qid2answer2weight.items():\n",
    "    pred_answer_dict['answer'][qid] = max(answer2weight.items(), key=operator.itemgetter(1))[0]\n",
    "    pred_answer_dict['sp'][qid] = []\n",
    "\n",
    "# Write answer to file\n",
    "pred_answer_filename = f'/Users/ethanperez/research_backup/scripts/ensembled_answers/nt={args.num_train}.st={args.sample_temperature}.num_seeds={args.num_seeds}.json'\n",
    "with open(pred_answer_filename, 'w') as f:\n",
    "    json.dump(pred_answer_dict, f)\n",
    "\n",
    "# Evaluate\n",
    "pred_answer_results = eval(pred_answer_filename, '/Users/ethanperez/research_backup/pytorch-transformers/data/hotpot-orig/dev.json')\n",
    "print(f'nt={args.num_train} ns={args.num_seeds} df={args.decay_factor}:', 100. * pred_answer_results['comparison_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
