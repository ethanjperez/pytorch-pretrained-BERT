{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "main_folder_name = 'research_backup'\n",
    "DATA_DIR = '{}/{}/data'.format(os.getenv('HOME'), main_folder_name)\n",
    "checkpoint_dir = os.getenv('HOME') + f'/{main_folder_name}/XLM/dumped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_no\",\n",
    "                    required=True,\n",
    "                    type=int,\n",
    "                    help=\"UMT generations model number.\")\n",
    "parser.add_argument(\"--sample_temperature\",\n",
    "                    required=True,\n",
    "                    type=float,\n",
    "                    help=\"UMT generations sampling temperature.\")\n",
    "parser.add_argument(\"--beam\",\n",
    "                    required=True,\n",
    "                    type=int,\n",
    "                    help=\"UMT generations beam size.\")\n",
    "parser.add_argument(\"--length_penalty\",\n",
    "                    required=True,\n",
    "                    type=float,\n",
    "                    help=\"UMT generations length penalty.\")\n",
    "parser.add_argument(\"--seed\",\n",
    "                    required=True,\n",
    "                    type=int,\n",
    "                    help=\"UMT generations seed.\")\n",
    "parser.add_argument(\"--split\",\n",
    "                    required=True,\n",
    "                    type=str,\n",
    "                    choices=['train_para', 'valid'],\n",
    "                    help=\"Dataset split.\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.model_no == 1:\n",
    "    model_dir = 'umt.comparison.paired.wp=0.15.sa=0.5.ebs=256.lr=0.0001.ws=0.wd=0.0.wb=0.0/17507568'\n",
    "elif args.model_no == 2:\n",
    "    model_dir = 'umt.comparison.paired.ebs=256.lr=0.0001.ws=0.wd=0.0.wb=0.03/17410140'\n",
    "else:\n",
    "    assert False, 'Bad model_no'\n",
    "subqs_filename = f'hyp.st={args.sample_temperature}.bs={args.beam}.lp={args.length_penalty}.es=False.seed={args.seed}.mh-sh.{args.split}.pred.bleu.sh.txt'\n",
    "\n",
    "subqs_filepath = os.path.join(checkpoint_dir, model_dir, subqs_filename)\n",
    "hotpot_split = args.split.replace('valid', 'dev').replace('_para', '')\n",
    "assert hotpot_split in {'train', 'dev', 'test'}\n",
    "\n",
    "with open(subqs_filepath) as f:\n",
    "    raw_subqs = f.readlines()\n",
    "print(f'Read {len(raw_subqs)} Sub-Q pairs')\n",
    "print(f'model_no={args.model_no}, st={args.sample_temperature}, beam={args.beam}, length_penalty={args.length_penalty}, seed={args.seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subqs = []\n",
    "for raw_subq in raw_subqs:\n",
    "    ex_subqs = raw_subq.strip('\\n').strip().split(' ?')\n",
    "    proc_ex_subqs = []\n",
    "    for ex_subq in ex_subqs:\n",
    "        proc_ex_subq = ex_subq.strip()\n",
    "        if len(proc_ex_subq) > 0:\n",
    "            proc_ex_subqs.append(proc_ex_subq + '?')\n",
    "    subqs.append(proc_ex_subqs)\n",
    "\n",
    "subq_lens = np.array([len(subq) for subq in subqs])\n",
    "print('Mean # of Sub-Qs:', round(subq_lens.mean(), 3))\n",
    "subqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DATA_DIR}/umt/comparison.paired/{args.split}.qids.txt') as f:\n",
    "    qids = f.readlines()\n",
    "qids = [qid.strip('\\n') for qid in qids]\n",
    "qid2subqs = {qid: subq_pair for qid, subq_pair in zip(qids, subqs)}\n",
    "print(f'Read {len(qids)} QIDs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DATA_DIR}/hotpot-all/{hotpot_split}.json') as f:\n",
    "    data_hotpot = json.load(f)\n",
    "\n",
    "num_hotpot_examples = len(data_hotpot['data'])\n",
    "print(f'Read {num_hotpot_examples} HotpotQA examples')\n",
    "qid2examples = {}\n",
    "for example in data_hotpot['data']:\n",
    "    qid = example['paragraphs'][0]['qas'][0]['id']\n",
    "    qid2examples[qid] = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_hotpot = {'data': []}\n",
    "for qid, subqpair in qid2subqs.items():\n",
    "    assert len(subqpair) > 0, 'There must be at least 1 Sub-Q!'\n",
    "    example = deepcopy(qid2examples[qid])\n",
    "    example['paragraphs'][0]['qas'] = [\n",
    "        {'question': subq,\n",
    "         'answers': [[] for _ in range(len(example['paragraphs'][0]['qas'][0]['answers']))],\n",
    "         'id': qid + '-' + str(i)}\n",
    "        for i, subq in enumerate(subqpair)]\n",
    "    new_data_hotpot['data'].append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f'{DATA_DIR}/hotpot-all.umt.comparison.paired.model={args.model_no}.st={args.sample_temperature}.beam={args.beam}.lp={float(args.length_penalty)}.seed={args.seed}'\n",
    "print('Saving to', save_dir)\n",
    "os.makedirs(save_dir, exist_ok=False)\n",
    "assert not os.path.isfile(f'{save_dir}/{hotpot_split}.json'), 'File already exists!'\n",
    "with open(f'{save_dir}/{hotpot_split}.json', 'w') as f:\n",
    "    json.dump(new_data_hotpot, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
